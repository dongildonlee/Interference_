{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39e8202-9a5c-4d50-b2b2-bf1b0dee21ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.append('../')\n",
    "\n",
    "from packages import actv_analysis, svm, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c646f-9eb6-4e57-85a0-238f99983661",
   "metadata": {},
   "source": [
    "## plot accuracy heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5444f43-e617-4d33-9d7a-6aefed9d0491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "net=1\n",
    "num_units=200\n",
    "\n",
    "for relu in range(2,3):\n",
    "    epoch_results = []\n",
    "    for epoch in np.arange(0,91,10):\n",
    "        exp_results = []\n",
    "        for exp in range(10):\n",
    "            test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "            pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "            exp_results.append(svm.get_svm_matrix(test_csv, pred_csv))\n",
    "        # Convert list of dataframes to 3D numpy array\n",
    "        data_3d = np.array([df.to_numpy() for df in exp_results])\n",
    "\n",
    "        # Compute mean along the first axis (the one representing different dataframes)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            avg_svm_matrix = np.nanmean(data_3d, axis=0)\n",
    "\n",
    "        # Convert back to DataFrame (if desired)\n",
    "        avg_svm_matrix_df = pd.DataFrame(avg_svm_matrix, index=exp_results[0].index, columns=exp_results[0].columns)\n",
    "        epoch_results.append(avg_svm_matrix_df)\n",
    "\n",
    "    # Create figure with 10 subplots arranged in a 5x2 grid\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(10,20))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        df = epoch_results[i]\n",
    "        sns.heatmap(df, cmap=\"rocket\", ax=ax, annot=True, cbar_kws={'label': 'accuracy'})\n",
    "        ax.set_xticklabels(np.arange(2, 21, 2))\n",
    "        ax.set_yticklabels(np.arange(2, 21, 2))\n",
    "        ax.set_title(f'Epoch {i*10}')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'svm_heatmap_for_relu{relu}_all_epochs_top{num_units}_monotonic_response_units.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e45345-c684-4b49-afab-0ac1f9663f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## number of units used in SVM vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf25d87-b668-4a8e-8cf7-3082317e04c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net=1\n",
    "relu=2\n",
    "epoch=90\n",
    "num_units=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79074998-7409-4e4f-b1ed-ca66bc0e209d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_epochs = []\n",
    "for epoch in range(0,91,10):\n",
    "    accuracies = []\n",
    "    for exp in range(10):\n",
    "        test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "        pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "\n",
    "        test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "        pred = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "        ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "        # Check for equality element-wise:\n",
    "        equal_elements = np.equal(pred, ans)\n",
    "        accuracies.append(np.sum(equal_elements)/len(test))\n",
    "    accuracy = np.mean(accuracies)\n",
    "    accuracy_epochs.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe97b910-a20d-4c3a-a6a6-7aa1d6c217e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# define the range for each variable\n",
    "nets = np.arange(1,3)\n",
    "relus = np.arange(5, 6, 1).astype(int)\n",
    "epochs = np.arange(0, 91, 10).astype(int)\n",
    "num_units = np.arange(200, 2001, 400).astype(int)\n",
    "\n",
    "# Create a cartesian product of all three lists\n",
    "all_combinations = list(product(nets, relus, epochs, num_units))\n",
    "\n",
    "# Convert the combinations into a dataframe\n",
    "df = pd.DataFrame(all_combinations, columns=['net', 'relu', 'epoch', 'num_units'])\n",
    "\n",
    "# Initially set accuracy to NaN (or some other default value)\n",
    "df['accuracy'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052555eb-d37a-498e-aa2f-5df459ce675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    net = int(row['net'])\n",
    "    relu = int(row['relu'])\n",
    "    epoch = int(row['epoch'])\n",
    "    num_units = int(row['num_units'])\n",
    "\n",
    "    accuracies = []\n",
    "    for exp in range(10):\n",
    "        test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "        pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "\n",
    "        test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "        pred = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "        ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "\n",
    "        # Check for equality element-wise:\n",
    "        equal_elements = np.equal(pred, ans)\n",
    "        accuracies.append(np.sum(equal_elements)/len(test))\n",
    "\n",
    "    df.at[idx, 'accuracy'] = np.mean(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cd19a-a417-422b-84d6-944563ab565f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'num_units' to a categorical type\n",
    "df['num_units'] = df['num_units'].astype('category')\n",
    "\n",
    "# Create a cubehelix color palette\n",
    "palette = sns.color_palette(\"cubehelix\", len(df['num_units'].unique()))\n",
    "\n",
    "sns.lineplot(data=df, x='epoch', y='accuracy', hue='num_units', palette=palette)\n",
    "plt.yticks = np.arange(0,91,10)\n",
    "plt.title(f'Relu{relu} epoch vs accuracy per number of units used in svm')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'Relu{relu} epoch vs accuracy per number of units used in svm.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10815a-442e-494b-8899-27599ecf0246",
   "metadata": {
    "tags": []
   },
   "source": [
    "## epoch & number distance vs congruency effect (accuracy of congruent - incongruent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff60cd-ce5a-42a4-84c9-dcf938b4a2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_num_sz_dist(test):\n",
    "    df_num_sz_dist = pd.DataFrame(index=range(len(test)), columns=['num_dist', 'sz_dist', 'congruency']) \n",
    "    df_num_sz_dist['num_dist'] = (test['num1'] - test['num2']) * 2\n",
    "    df_num_sz_dist['sz_dist'] = test['sz1'] - test['sz2']\n",
    "    df_num_sz_dist['congruency'] = np.sign(df_num_sz_dist['num_dist']) == np.sign(df_num_sz_dist['sz_dist']) \n",
    "    return df_num_sz_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5c406-484d-4c45-a409-0c8d53bc03d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# define the range for each variable\n",
    "nets = np.arange(1,3)\n",
    "relus = np.arange(5, 6, 1).astype(int)\n",
    "epochs = np.arange(0, 91, 10).astype(int)\n",
    "num_units = np.arange(200, 2001, 400).astype(int)\n",
    "\n",
    "# Create a cartesian product of all three lists\n",
    "all_combinations = list(product(nets, relus, epochs, num_units))\n",
    "\n",
    "# Convert the combinations into a dataframe\n",
    "df = pd.DataFrame(all_combinations, columns=['net', 'relu', 'epoch', 'num_units'])\n",
    "\n",
    "# Initially set accuracy to NaN (or some other default value)\n",
    "df['accuracy'] = np.nan\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    net = int(row['net'])\n",
    "    relu = int(row['relu'])\n",
    "    epoch = int(row['epoch'])\n",
    "    num_units = int(row['num_units'])\n",
    "\n",
    "    accuracies = []\n",
    "    for exp in range(10):\n",
    "        test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "        pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "\n",
    "        test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "        df_num_sz_dist = get_num_sz_dist(test)\n",
    "        pred = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "        ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "\n",
    "        # Check for equality element-wise:\n",
    "        equal_elements = np.equal(pred, ans)\n",
    "        df_num_sz_dist['correctly_predicted'] = equal_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d540b1-4b8f-4166-90ca-3ec947a8e5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the ranges\n",
    "nets = range(1, 2)\n",
    "relus = range(5, 6)\n",
    "num_units_values = range(2000, 2001, 200)\n",
    "epochs = range(0, 91, 10)\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = product(nets, relus, num_units_values, epochs)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(combinations, columns=['net', 'relu', 'num_units', 'epoch'])\n",
    "\n",
    "# Add the 'cong_effect' column\n",
    "df['cong_effect'] = np.nan\n",
    "\n",
    "for net in range(1,2):\n",
    "    for relu in range(5,6):\n",
    "        for num_units in range(2000,2001,200):\n",
    "            for epoch in range(0,91,10):\n",
    "                test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "                pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "\n",
    "                test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "                df_num_sz_dist = get_num_sz_dist(test)\n",
    "                pred = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "                ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "\n",
    "                # Check for equality element-wise:\n",
    "                equal_elements = np.equal(pred, ans)\n",
    "                df_num_sz_dist['correctly_predicted'] = equal_elements\n",
    "\n",
    "                #accs  = []\n",
    "                for nd in range(2,19,2):\n",
    "                    df_numdist = df_num_sz_dist[np.abs(df_num_sz_dist['num_dist']) == nd]\n",
    "                    df_numdist_cong = df_numdist[df_numdist['congruency']==True]\n",
    "                    accuracy_cong = np.sum(df_numdist_cong['correctly_predicted'])/len(df_numdist_cong)\n",
    "                    df_numdist_incong = df_numdist[df_numdist['congruency']==False]\n",
    "                    accuracy_incong = np.sum(df_numdist_incong['correctly_predicted'])/len(df_numdist_incong)\n",
    "                    cong_effect = accuracy_cong - accuracy_incong\n",
    "                    #accs.append(cong_effect)\n",
    "                    # Fill df at the appropriate location            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd770d-d6aa-487e-ad8e-595f85a3c7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the ranges\n",
    "nets = range(1, 3)\n",
    "relus = range(2, 6)\n",
    "num_units_values = range(200, 2001, 200)\n",
    "epochs = range(0, 91, 10)\n",
    "num_dists = range(2, 19, 2)\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = product(nets, relus, num_units_values, epochs, num_dists)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(combinations, columns=['net', 'relu', 'num_units', 'epoch', 'num_dist'])\n",
    "\n",
    "# Add the 'cong_effect' column\n",
    "df['cong_effect'] = np.nan\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    net = int(row['net'])\n",
    "    relu = int(row['relu'])\n",
    "    num_units = int(row['num_units'])\n",
    "    epoch = int(row['epoch'])\n",
    "    num_dist = int(row['num_dist'])\n",
    "    \n",
    "    test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "    pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "\n",
    "    test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "    df_num_sz_dist = get_num_sz_dist(test)\n",
    "    pred = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "    ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "\n",
    "    # Check for equality element-wise:\n",
    "    equal_elements = np.equal(pred, ans)\n",
    "    df_num_sz_dist['correctly_predicted'] = equal_elements\n",
    "\n",
    "    df_numdist = df_num_sz_dist[np.abs(df_num_sz_dist['num_dist']) == num_dist]\n",
    "    df_numdist_cong = df_numdist[df_numdist['congruency']==True]\n",
    "    accuracy_cong = np.sum(df_numdist_cong['correctly_predicted'])/len(df_numdist_cong)\n",
    "    df_numdist_incong = df_numdist[df_numdist['congruency']==False]\n",
    "    accuracy_incong = np.sum(df_numdist_incong['correctly_predicted'])/len(df_numdist_incong)\n",
    "    cong_effect = accuracy_cong - accuracy_incong\n",
    "\n",
    "    # Fill df at the appropriate location\n",
    "    df.at[index, 'cong_effect'] = cong_effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acefc3-af71-402c-a347-73d6f367a08b",
   "metadata": {},
   "source": [
    "### Generate congruency effect heatmap per network and relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf06613-d18a-4bd2-8b38-2d4d689334d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_val = df['cong_effect'].min()\n",
    "max_val = df['cong_effect'].max()\n",
    "\n",
    "for net in nets:\n",
    "    for relu in relus:\n",
    "        for num_unit in num_units_values:\n",
    "            df_sub = df[(df['net']==net) & (df['relu']==relu) & (df['num_units']==num_unit)]\n",
    "            \n",
    "            # Reshape the dataframe\n",
    "            pivot_df = df_sub.pivot(index='num_dist', columns='epoch', values='cong_effect')\n",
    "\n",
    "            # Create the heatmap\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(pivot_df, annot=True, cmap='rocket', vmin=min_val, vmax=max_val)\n",
    "            plt.title(f'Congruency effect net{net} relu {relu} {num_unit} units')\n",
    "            plt.savefig(f'heatmap for congruency effect of net{net} relu{relu} epoch{epoch} {num_unit} nonzero activity units July2023.pdf')\n",
    "            #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9e78c-bd5c-4043-b5a2-1c9f5bc16331",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generate congruency effect heatmap per relu (averaged across networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fd8b3-b676-478f-9245-fb5c7eebe9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate average 'cong_effect' across all nets\n",
    "df_avg = df.groupby(['num_dist', 'epoch', 'relu', 'num_units']).mean().reset_index()\n",
    "\n",
    "# Find global min and max of 'cong_effect'\n",
    "min_val = df_avg['cong_effect'].min()\n",
    "max_val = df_avg['cong_effect'].max()\n",
    "\n",
    "for relu in range(3,6):\n",
    "    for num_unit in num_units_values:\n",
    "        df_sub = df_avg[(df_avg['relu']==relu) & (df_avg['num_units']==num_unit)]\n",
    "\n",
    "        # Reshape the dataframe\n",
    "        pivot_df = df_sub.pivot(index='num_dist', columns='epoch', values='cong_effect')\n",
    "\n",
    "        # Create the heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot_df, annot=True, cmap='rocket', vmin=min_val, vmax=max_val)\n",
    "        plt.title(f'Average congruency effect for relu {relu} with {num_unit} units')\n",
    "        plt.savefig(f'heatmap for average congruency effect of relu{relu} with {num_unit} units July2023.pdf')\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b8b57-8f72-477b-937d-ca91458a35e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Calculate average 'cong_effect' across all nets\n",
    "df_avg = df.groupby(['num_dist', 'epoch', 'relu', 'num_units']).mean().reset_index()\n",
    "\n",
    "# Find global min and max of 'cong_effect'\n",
    "min_val = df_avg['cong_effect'].min()\n",
    "max_val = df_avg['cong_effect'].max()\n",
    "\n",
    "for relu in range(2, 6):\n",
    "    # Define number of rows and columns for subplot\n",
    "    num_unit_len = len(num_units_values)\n",
    "    num_cols = 2\n",
    "    num_rows = math.ceil(num_unit_len / num_cols)\n",
    "\n",
    "    # Create figure and axes for each relu\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(10 * num_cols, 8 * num_rows))  # Adjust the figure size\n",
    "\n",
    "    # To handle cases when the number of subplots is not exactly filling the grid\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i, num_unit in enumerate(num_units_values):\n",
    "        df_sub = df_avg[(df_avg['relu'] == relu) & (df_avg['num_units'] == num_unit)]\n",
    "\n",
    "        # Reshape the dataframe\n",
    "        pivot_df = df_sub.pivot(index='num_dist', columns='epoch', values='cong_effect')\n",
    "\n",
    "        # Create the heatmap on specific subplot\n",
    "        sns.heatmap(pivot_df, annot=True, cmap='rocket', vmin=min_val, vmax=max_val, ax=axs[i])\n",
    "        axs[i].set_title(f'Average congruency effect for relu {relu} with {num_unit} units')\n",
    "\n",
    "    # Remove unused subplots\n",
    "    for j in range(i+1, num_rows * num_cols):\n",
    "        fig.delaxes(axs[j])\n",
    "\n",
    "    # Save the full figure for each relu\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'heatmaps for average congruency effect of relu {relu} July2023.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dec819-0576-48e2-940e-e12ed5e19c60",
   "metadata": {},
   "source": [
    "### Lineplot for epoch vs congruency effect (for num units used 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b7da1-4fd9-4853-a563-a33c7c87fe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get unique num_dist values\n",
    "num_dist_values = df['num_dist'].unique()\n",
    "\n",
    "# Define number of rows and columns for subplot\n",
    "num_dist_len = len(num_dist_values)\n",
    "num_cols = 3  # Number of columns in the subplot grid\n",
    "num_rows = int(np.ceil(num_dist_len / num_cols))  # Calculate number of rows needed\n",
    "\n",
    "# Create figure and axes for each num_dist\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10*num_cols, 8*num_rows))  # Adjust the figure size\n",
    "\n",
    "# Flatten axs for easy iteration\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Determine the global y-axis limits\n",
    "global_y_min = df['cong_effect'].min()\n",
    "global_y_max = df['cong_effect'].max()\n",
    "\n",
    "# Get the unique 'relu' values and create a color map for them\n",
    "relu_values = df['relu'].unique()\n",
    "\n",
    "# Make sure the length of relu_values does not exceed the number of specified colors\n",
    "assert len(relu_values) <= 4, \"There are more 'relu' values than colors specified\"\n",
    "\n",
    "colors = ['red', 'orange', 'green', 'blue']\n",
    "color_dict = dict(zip(relu_values, colors))\n",
    "\n",
    "for i, num_dist in enumerate(num_dist_values):\n",
    "    df_sub = df[(df['num_dist']==num_dist)&(df['num_units']==200)]\n",
    "\n",
    "    # Create the line plot on specific subplot\n",
    "    sns.lineplot(data=df_sub, x='epoch', y='cong_effect', hue='relu', palette=color_dict, ax=axs[i])\n",
    "    axs[i].set_title(f'Congruency effect for num_dist {num_dist}', fontsize=20)\n",
    "\n",
    "    # Set the same y-axis limit for all subplots\n",
    "    axs[i].set_ylim(global_y_min, global_y_max)\n",
    "\n",
    "    # Set the x-ticks\n",
    "    axs[i].set_xticks(range(0, 91, 10))\n",
    "    \n",
    "    # Set x-axis and y-axis label size\n",
    "    axs[i].tick_params(axis='x', labelsize=16)\n",
    "    axs[i].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "    # Increase legend size\n",
    "    leg = axs[i].legend()\n",
    "    for t in leg.texts:\n",
    "        t.set_fontsize(16)\n",
    "        \n",
    "    # Increase axes label size\n",
    "    axs[i].xaxis.label.set_size(16)\n",
    "    axs[i].yaxis.label.set_size(16)\n",
    "    \n",
    "    axs[i].set_ylabel(\"congruency effect\", fontsize=16)\n",
    "\n",
    "# Remove empty subplots\n",
    "if num_dist_len % num_cols != 0:\n",
    "    for ax in axs[num_dist_len:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "# Set the layout to tight to avoid overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59812b1-3284-4f60-ac61-dcd0f311281e",
   "metadata": {},
   "source": [
    "### Lineplot for Relu vs Congruency effect per epoch number distance (a figure per number distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26403f60-9edf-4787-9962-178fafa8c873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for nd in np.arange(2,19,2):\n",
    "\n",
    "    # Generate line plot\n",
    "    df_sub = df[(df['num_units']==200) & (df['num_dist']==nd)]\n",
    "    ax = sns.lineplot(data=df_sub, x='relu',y='cong_effect',hue='epoch',err_style='bars', palette='viridis')\n",
    "\n",
    "    # Set x-ticks\n",
    "    ax.set_xticks(range(3,6))\n",
    "\n",
    "    # Draw a red dotted horizontal line at y=0\n",
    "    ax.axhline(0, color='red', linestyle='--')\n",
    "\n",
    "    # Set y-label\n",
    "    ax.set_ylabel('Congruency Effect')\n",
    "\n",
    "    # Move legend outside the figure\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.85, box.height]) # shrink figure by 15%\n",
    "    legend = ax.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1) \n",
    "\n",
    "    # Set the legend title\n",
    "    legend.set_title('epoch')\n",
    "    ax.set_title(f'number distance:{nd}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Lineplot for Relu vs Congruency effect per epoch number distance {num_dist}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d383e6-bf7e-4558-895c-d342cd475a1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lineplot for Relu vs Congruency effect per epoch number distance (a subplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1f5ad-d2a7-499b-a74f-20710f038cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the size and layout of the subplots\n",
    "num_dist_values = np.arange(2,7,2)\n",
    "num_dist_len = len(num_dist_values)\n",
    "num_cols = 3\n",
    "num_rows = int(np.ceil(num_dist_len / num_cols))\n",
    "\n",
    "# Create the figure and axes for the subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 5))\n",
    "\n",
    "# Flatten the axes for easy iteration\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Get global y-axis limits\n",
    "global_y_min = df['cong_effect'].min()\n",
    "global_y_max = df['cong_effect'].max()\n",
    "\n",
    "lines_labels = []\n",
    "\n",
    "for i, nd in enumerate(num_dist_values):\n",
    "    # Generate line plot\n",
    "    df_sub = df[(df['num_units']==200) & (df['num_dist']==nd)]\n",
    "    ax = sns.lineplot(data=df_sub, x='relu', y='cong_effect', hue='epoch', err_style='bars', palette='viridis', ax=axs[i])\n",
    "\n",
    "    # Set y-axis limits\n",
    "    axs[i].set_ylim(global_y_min, global_y_max)\n",
    "\n",
    "    # Set x-ticks\n",
    "    axs[i].set_xticks(range(2,6))\n",
    "\n",
    "    # Draw a red dotted horizontal line at y=0\n",
    "    axs[i].axhline(0, color='red', linestyle='--')\n",
    "\n",
    "    # Set y-label\n",
    "    axs[i].set_xlabel('ReLu')\n",
    "    axs[i].set_ylabel('Congruency Effect')\n",
    "\n",
    "    # Set subplot title\n",
    "    axs[i].set_title(f'number distance: {nd}')\n",
    "\n",
    "    # Get the Line2D objects from the Axes object\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines_labels.append((lines, labels))\n",
    "\n",
    "    # Remove the legend of each subplot\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "# Remove extra subplots\n",
    "if num_dist_len % num_cols != 0:\n",
    "    for ax in axs[num_dist_len:]:\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "# Adjust layout to avoid overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create a new legend for the figure using the handles and labels we collected\n",
    "lines, labels = lines_labels[0]  # All subplots have the same legend, so use the first one\n",
    "fig.legend(lines, labels, title='epoch', loc='lower center', ncol=len(lines), bbox_to_anchor=(0.5, -0.1))\n",
    "plt.tight_layout()\n",
    "# Save the figure\n",
    "plt.savefig('Lineplot for Relu vs Congruency effect per epoch for different number distances.pdf',bbox_inches='tight')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcfd41-65dc-417a-af8a-5a5d291d0b66",
   "metadata": {},
   "source": [
    "## Analysis of how different types of monotonic units (LNLS and LNSS) affect learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344dd583-c127-44c6-8fbe-788625d9ec4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the ranges\n",
    "nets = range(1, 3)\n",
    "relus = range(4, 5)\n",
    "num_units_values = range(200, 201, 200)\n",
    "epochs = range(90, 91, 10)\n",
    "num_dists = range(2, 19, 2)\n",
    "LNSS_prop = np.arange(0,1.1,0.1)\n",
    "\n",
    "\n",
    "# Generate all combinations\n",
    "combinations = product(nets, relus, num_units_values, epochs, LNSS_prop, num_dists)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(combinations, columns=['net', 'relu', 'num_units', 'epoch', 'LNSS_prop', 'num_dist'])\n",
    "\n",
    "# Add the 'cong_effect' column\n",
    "df['cong_effect'] = np.nan\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    net = int(row['net'])\n",
    "    relu = int(row['relu'])\n",
    "    num_units = int(row['num_units'])\n",
    "    epoch = int(row['epoch'])\n",
    "    num_dist = int(row['num_dist'])\n",
    "    LNSS_prop = round(row['LNSS_prop'], 1)\n",
    "    LNLS_prop = round(1-LNSS_prop, 1)\n",
    "    pred_csv = f'csv/svm_results/SVM_prediction_of_He_untrained_net{net}_relu{relu}_epoch{epoch}_{int(100*LNSS_prop)}_percent_LNSS_and_{int(100*LNLS_prop)}_percent_LNLS_units_exp{exp}_July2023.csv'\n",
    "    \n",
    "    test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "    pred_csv = f'csv/svm_results/SVM_prediction_of_He_untrained_net{net}_relu{relu}_epoch{epoch}_{int(100*LNSS_prop)}_percent_LNSS_and_{int(100*LNLS_prop)}_percent_LNLS_units_exp{exp}_July2023.csv'\n",
    "\n",
    "    test = pd.read_csv(test_csv).drop('Unnamed: 0', axis=1)\n",
    "    df_num_sz_dist = get_num_sz_dist(test)\n",
    "    pred = pd.read_csv(pred_csv)['y_pred'].to_numpy()\n",
    "    ans = svm.get_y(pd.read_csv(test_csv).drop('Unnamed: 0', axis=1))  # Assumes that get_y is defined elsewhere\n",
    "\n",
    "    # Check for equality element-wise:\n",
    "    equal_elements = np.equal(pred, ans)\n",
    "    df_num_sz_dist['correctly_predicted'] = equal_elements\n",
    "\n",
    "    df_numdist = df_num_sz_dist[np.abs(df_num_sz_dist['num_dist']) == num_dist]\n",
    "    df_numdist_cong = df_numdist[df_numdist['congruency']==True]\n",
    "    accuracy_cong = np.sum(df_numdist_cong['correctly_predicted'])/len(df_numdist_cong)\n",
    "    df_numdist_incong = df_numdist[df_numdist['congruency']==False]\n",
    "    accuracy_incong = np.sum(df_numdist_incong['correctly_predicted'])/len(df_numdist_incong)\n",
    "    cong_effect = accuracy_cong - accuracy_incong\n",
    "\n",
    "    # Fill df at the appropriate location\n",
    "    df.at[index, 'cong_effect'] = cong_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10864602-ec97-4ecf-96bf-272a2d27f0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.lineplot(data=df, x='LNSS_prop', y='cong_effect', hue='num_dist', palette='tab10')\n",
    "ax.set_xlabel('Proportion of LNSS units', fontsize=14)\n",
    "ax.set_xticks(np.arange(0,1.1,0.2))\n",
    "ax.set_ylabel('Congruency effect', fontsize=14)\n",
    "ax.set_title('Congruency effect by proportion of LNSS units', fontsize=16)\n",
    "plt.axvline(0.5, color='red', linestyle='dotted')  # Adds a vertical dotted line at x=0.5\n",
    "plt.savefig('Congruency effect by proportion of LNSS units.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f91d46-0bc9-401b-bca9-6884398418c4",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54054449-843d-44c2-a517-db7773590f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pdist = pd.read_csv('pdist.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701de84-6bcc-45c9-9d01-e0344e460504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute num_dist for each row\n",
    "df_pdist['num_dist'] = abs(df_pdist['num1'] - df_pdist['num2'])\n",
    "\n",
    "# Define congruency\n",
    "df_pdist['is_congruent'] = ((df_pdist['num1'] < df_pdist['num2']) & (df_pdist['sz1'] < df_pdist['sz2'])) | ((df_pdist['num1'] > df_pdist['num2']) & (df_pdist['sz1'] > df_pdist['sz2']))\n",
    "\n",
    "# Empty DataFrame to store the result\n",
    "df_new = pd.DataFrame(columns=['num_dist', 'pdist_congruency_effect'])\n",
    "\n",
    "# Loop over each unique num_dist\n",
    "for num_dist in df_pdist['num_dist'].unique():\n",
    "    df_same_num_dist = df_pdist[df_pdist['num_dist'] == num_dist]\n",
    "\n",
    "    # Mean pdist for congruent and incongruent conditions\n",
    "    mean_pdist_congruent = df_same_num_dist[df_same_num_dist['is_congruent']]['pdist'].mean()\n",
    "    mean_pdist_incongruent = df_same_num_dist[~df_same_num_dist['is_congruent']]['pdist'].mean()\n",
    "\n",
    "    # Compute pdist_congruency_effect\n",
    "    pdist_congruency_effect = mean_pdist_congruent - mean_pdist_incongruent\n",
    "\n",
    "    # Append to the result DataFrame\n",
    "    df_new = pd.concat([df_new, pd.DataFrame([{'num_dist': num_dist, 'pdist_congruency_effect': pdist_congruency_effect}])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc3262-906c-4948-83fd-965ea681eba3",
   "metadata": {},
   "source": [
    "## Euclidean distance in MDS vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc090e07-a86f-409b-aea8-805eb5e28262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net1 relu2 epoch0\n",
      "--- 356.467631816864 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "df_pdist_list = []\n",
    "\n",
    "# Iterate through relu, epoch, and net\n",
    "for relu in range(2,6):\n",
    "    for epoch in range(0,91,10):\n",
    "        for net in range(1,3):\n",
    "            print(f'net{net} relu{relu} epoch{epoch}')\n",
    "            # Store the cosine similarity results for each epoch in a dictionary\n",
    "            cs_dict = stats.cos_similarity(relu=relu, epoch=epoch, nets=range(net, net+1))\n",
    "            \n",
    "            # Perform MDS\n",
    "            mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "            mds_results = mds.fit_transform(1 - cs_dict)\n",
    "            \n",
    "            # Calculate pairwise distances and convert to square form\n",
    "            dist_matrix = squareform(pdist(mds_results))\n",
    "\n",
    "            # Initialize lists to hold the data\n",
    "            index1_list, index2_list, pdist_list = [], [], []\n",
    "\n",
    "            # Iterate over pairs of points (upper triangular matrix indices)\n",
    "            for i in range(dist_matrix.shape[0]):\n",
    "                for j in range(i+1, dist_matrix.shape[1]):\n",
    "                    # Store the indices and the distance in the lists\n",
    "                    index1_list.append(i)\n",
    "                    index2_list.append(j)\n",
    "                    pdist_list.append(dist_matrix[i, j])\n",
    "\n",
    "            # Create the DataFrame\n",
    "            df_pdist = pd.DataFrame({\n",
    "                'index1': index1_list,\n",
    "                'index2': index2_list,\n",
    "                'pdist': pdist_list,\n",
    "                'relu': relu,\n",
    "                'epoch': epoch,\n",
    "                'net': net\n",
    "            })\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            df_pdist_list.append(df_pdist)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_final = pd.concat(df_pdist_list, ignore_index=True)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600e496-4431-418e-91fe-2e7aea5b106b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the long format DataFrames\n",
    "long_df_list = []\n",
    "\n",
    "for relu in range(2,3):\n",
    "    for epoch in np.arange(0,91,10):\n",
    "        exp_results = []\n",
    "        for exp in range(10):\n",
    "            test_csv = f'csv/svm_test_set{exp}.csv'\n",
    "            pred_csv = f'csv/svm_results/SVM prediction of He untrained net{net} relu{relu} epoch{epoch} {num_units} nonzero activity units exp{exp} June2023.csv'\n",
    "            exp_results.append(svm.get_svm_matrix(test_csv, pred_csv))\n",
    "\n",
    "        # Convert list of dataframes to 3D numpy array\n",
    "        data_3d = np.array([df.to_numpy() for df in exp_results])\n",
    "\n",
    "        # Compute mean along the first axis (the one representing different dataframes)\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            avg_svm_matrix = np.nanmean(data_3d, axis=0)\n",
    "\n",
    "        # Convert back to DataFrame (if desired)\n",
    "        avg_svm_matrix_df = pd.DataFrame(avg_svm_matrix, index=exp_results[0].index, columns=exp_results[0].columns)\n",
    "\n",
    "        # Melt the DataFrame to long format and add the corresponding relu, epoch and experiment number\n",
    "        df_long = avg_svm_matrix_df.reset_index().melt(id_vars='index', var_name='column', value_name='value')\n",
    "        \n",
    "        # Change 'index' and 'column' to 'num1' and 'num2' and map the number from 0 - 9 to 2 to 20 with step size of 2\n",
    "        df_long.rename(columns={'index': 'num1', 'column': 'num2'}, inplace=True)\n",
    "        df_long['num1'] = df_long['num1'].astype(int) * 2 + 2\n",
    "        df_long['num2'] = df_long['num2'].astype(int) * 2 + 2\n",
    "        \n",
    "        # Determine if it is congruent or not (upper triangle = True, lower triangle = False)\n",
    "        df_long['congruent'] = df_long['num1'] < df_long['num2']\n",
    "        \n",
    "        # Add the relu, epoch and experiment number\n",
    "        df_long['relu'] = relu\n",
    "        df_long['epoch'] = epoch\n",
    "        df_long['exp'] = exp\n",
    "\n",
    "        # Reorder the columns\n",
    "        df_long = df_long[['num1', 'num2', 'congruent', 'relu', 'epoch', 'exp', 'value']]\n",
    "\n",
    "        # Append the long format DataFrame to the list\n",
    "        long_df_list.append(df_long)\n",
    "\n",
    "# Concatenate all the long format DataFrames\n",
    "df_final = pd.concat(long_df_list, ignore_index=True)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81443ef-8edb-4e02-bfe5-b4f383b69861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame so that the indices become a column\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "df_long = df_reset.melt(id_vars='index', var_name='column', value_name='value')\n",
    "\n",
    "# Rename the columns to more meaningful names\n",
    "df_long = df_long.rename(columns={'index': 'axis1', 'column': 'axis2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd7043-82c7-4c6c-9b22-317cc7ce69ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d1d83-729c-44cd-90ed-7c28e03dab3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
