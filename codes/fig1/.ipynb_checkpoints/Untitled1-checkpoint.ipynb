{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8677b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.append('../')\n",
    "from packages import actv_analysis, svm, load_csv, stats, objects\n",
    "import pickle\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Parameters ########################\n",
    "relu=4\n",
    "nets = range(4,11)\n",
    "epochs= range(0,91,10)\n",
    "\n",
    "numbers = range(2,21,2)\n",
    "min_sz_idx=3; max_sz_idx=9\n",
    "sizes = np.arange(4,14)[min_sz_idx: max_sz_idx+1]\n",
    "inst = 500\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in range(1,11):\n",
    "    for relu in range(3,4):\n",
    "        for epoch in range(0,91,10):\n",
    "            try:\n",
    "                stats.complete_anova2(net=net,relu=relu,epoch=epoch)\n",
    "            except objects.Anova2ExistsError as e:\n",
    "                continue  # Skips to the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pkl_fin_anova2(net=1,relu=4,epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6a200",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1\n",
    "relu=4\n",
    "epoch=0\n",
    "\n",
    "# Load the pickle file\n",
    "with open(f'network{net}_Relu{relu}_epoch{epoch}.pkl', 'rb') as f:\n",
    "    units = pickle.load(f)\n",
    "\n",
    "# Identify the units for which ANOVA2 needs to be re-calculated\n",
    "units_to_recalculate = np.array([i for i in range(len(units)) if (units[i].anova2 is None or units[i].anova2.isna().all().all()) and not units[i].no_response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11703d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(units_to_recalculate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6c24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sz_idx=3; max_sz_idx=9; numbers=range(2,21,2); inst=500\n",
    "actv_net = actv_analysis.get_actv_net(net=net, relu=relu, epoch=epoch)\n",
    "take = np.arange(0,100).reshape(10,10)[:,min_sz_idx:max_sz_idx+1].reshape(len(numbers)*(max_sz_idx-min_sz_idx+1))\n",
    "\n",
    "actv_szAtoB = actv_net[:,take,:]\n",
    "actv_2D = actv_szAtoB.reshape(actv_szAtoB.shape[0], actv_szAtoB.shape[1]*actv_szAtoB.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba117b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array([not np.all(actv_2D[unit_idx,:] == 0) for unit_idx in units_to_recalculate])\n",
    "kk = units_to_recalculate[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5371516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in range(1,11):\n",
    "    for relu in range(4,6):\n",
    "        for epoch in range(0,91,10):\n",
    "            stats.complete_anova2(net=net,relu=relu,epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,91,10):  # Assuming 10 epochs\n",
    "    stats.cos_similarity(5, epoch,nets=range(1,3), min_sz_idx=9, max_sz_idx=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b76575",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=5; epoch=10\n",
    "with open(f'network{net}_Relu{relu}_epoch{epoch}.pkl', 'rb') as f:\n",
    "    units = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_to_recalculate = np.array([i for i in range(len(units)) if not units[i].no_response and (units[i].anova2 is None or units[i].anova2.isna().all().all())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b508245",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_to_recalculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in range(1,11):\n",
    "    for relu in range(5,6):\n",
    "        for epoch in range(0,91,10):\n",
    "            objects.update_incomplete_units(net=net,relu=relu,epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(net, relu, epoch):\n",
    "    objects.update_incomplete_units(net=net,relu=relu,epoch=epoch)\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(process)(net, relu, epoch) for net in range(7,11) for relu in range(4,6) for epoch in range(0,91,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83460874",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=2; relu=4; epoch=0\n",
    "pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "with open(pickle_filename, 'rb') as f:\n",
    "    units = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdb1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = units[0].missing_attributes(units[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6b9377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_reponse', 'PN', 'oPN', 'PS', 'oPS']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25abf017",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = actv_analysis.get_blocks(63264,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=3; epoch=10\n",
    "\n",
    "pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "with open(pickle_filename, 'rb') as f:\n",
    "    units = pickle.load(f)\n",
    "\n",
    "units_to_recalculate = np.array([i for i in range(len(units)) if not units[i].no_response_subset and (units[i].anova2 is None or units[i].anova2.isna().all().all())])\n",
    "actv_net = actv_analysis.get_actv_net(net=net, relu=relu, epoch=epoch)\n",
    "take = np.arange(0,100).reshape(10,10)[:,min_sz_idx:max_sz_idx+1].reshape(len(numbers)*(max_sz_idx-min_sz_idx+1))\n",
    "no_response_subset = np.all(actv_net[:,take,:] == 0, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(no_response_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02d871ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 76.3555018901825 seconds ---\n"
     ]
    }
   ],
   "source": [
    "actv = actv_analysis.get_actv_net(net, relu, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adcbd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_id = 1\n",
    "numbers = range(2,21,2)\n",
    "min_sz_idx=3; max_sz_idx=9\n",
    "sizes = np.arange(4,14)\n",
    "min_sz_idx=3; max_sz_idx=9\n",
    "#take = np.arange(0,100).reshape(10,10)[:,min_sz_idx:max_sz_idx+1].reshape(len(numbers)*(max_sz_idx-min_sz_idx+1))\n",
    "\n",
    "avg_actv = np.nanmean(actv, axis=2)\n",
    "avg_actv_nxs_ = avg_actv.reshape(actv.shape[0], len(numbers), len(sizes))\n",
    "avg_actv_nxs = avg_actv_nxs_[:,:,min_sz_idx:max_sz_idx+1]\n",
    "# PN_by_size = numbers[np.argmax(avg_actv_nxs, axis=1)]\n",
    "# oPN = numbers[np.argmax(np.mean(avg_actv_nxs,axis=2),axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9556b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64896, 7)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(avg_actv_nxs, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6488d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64896, 10, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_actv_nxs_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e9626fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(avg_actv[:, 0:10].ravel(), avg_actv.reshape(actv.shape[0], len(numbers), len(sizes))[:, 0, :].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ed15f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(avg_actv_nxs_, unit_id, numbers, min_sizes, max_sizes):\n",
    "    df = pd.DataFrame(index=min_sizes, columns=max_sizes)\n",
    "    for min_sz in min_sizes:\n",
    "        for max_sz in max_sizes:\n",
    "            avg_actv_nxs = avg_actv_nxs_[unit_id,:,min_sz:max_sz+1]\n",
    "            pn_indices = np.argmax(avg_actv_nxs, axis=1)\n",
    "    return pn_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86472f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sizes = range(0,10)\n",
    "max_sizes = range(0,10)\n",
    "\n",
    "avg_actv = np.nanmean(actv, axis=2)\n",
    "avg_actv_nxs_ = avg_actv.reshape(actv.shape[0], len(numbers), len(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a0c39a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of original method: 0.0017850399017333984 seconds.\n"
     ]
    }
   ],
   "source": [
    "min_sizes = range(0,10)\n",
    "max_sizes = range(0,10)\n",
    "\n",
    "df = pd.DataFrame(index=sizes, columns=sizes)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for min_sz in min_sizes:\n",
    "    for max_sz in max_sizes:\n",
    "        if max_sz < min_sz: # if max_sz is smaller, skip this iteration\n",
    "            continue\n",
    "\n",
    "        if min_sz == max_sz:\n",
    "            avg_actv_nxs = avg_actv_nxs_[unit_id,:,min_sz]\n",
    "        else:\n",
    "            avg_actv_nxs = avg_actv_nxs_[unit_id,:,min_sz:max_sz]\n",
    "            \n",
    "        PN = numbers[np.argmax(avg_actv_nxs)]\n",
    "        df.at[sizes[min_sz], sizes[max_sz]] = PN\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time of original method: {end_time - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d54ce8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time of optimized method: 0.003392934799194336 seconds.\n"
     ]
    }
   ],
   "source": [
    "result = np.zeros((len(sizes), len(sizes)))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for min_sz, max_sz in product(min_sizes, max_sizes):\n",
    "    if max_sz >= min_sz:\n",
    "        if min_sz == max_sz:\n",
    "            avg_actv_nxs = avg_actv_nxs_[unit_id,:,min_sz]\n",
    "        else:\n",
    "            avg_actv_nxs = avg_actv_nxs_[unit_id,:,min_sz:max_sz]\n",
    "            \n",
    "        PN = numbers[np.argmax(avg_actv_nxs)]\n",
    "        result[min_sz, max_sz] = PN\n",
    "\n",
    "df_optimized = pd.DataFrame(result, index=sizes, columns=sizes)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time of optimized method: {end_time - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "056dd916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_PS(self, avg_actv_nxs_):\n",
    "    min_sizes = range(0,10)\n",
    "    max_sizes = range(0,10)\n",
    "    sizes = np.arange(4,14)\n",
    "\n",
    "    result = np.zeros((len(sizes), len(sizes)))\n",
    "\n",
    "    for min_sz, max_sz in product(min_sizes, max_sizes):\n",
    "        if max_sz >= min_sz:\n",
    "            if min_sz == max_sz:\n",
    "                avg_actv_nxs = avg_actv_nxs_[self.id,:,min_sz]\n",
    "            else:\n",
    "                avg_actv_nxs = avg_actv_nxs_[self.id,:,min_sz:max_sz]\n",
    "                \n",
    "            PS = sizes[np.argmax(avg_actv_nxs)]\n",
    "            result[min_sz, max_sz] = PS\n",
    "\n",
    "    df_PS = pd.DataFrame(result, index=sizes, columns=sizes)\n",
    "\n",
    "    return df_PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aac7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in range(1,11):\n",
    "    for relu in range(4,6):\n",
    "        for epoch in range(0,91,10):\n",
    "            print(f'network{net}_Relu{relu}_epoch{epoch}')\n",
    "            pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "            with open(pickle_filename, 'rb') as f:\n",
    "                units = pickle.load(f)\n",
    "            avtv_net = actv_analysis.get_actv_net(net=net, relu=relu, epoch=epoch)\n",
    "            avg_actv_nxs_ = avg_actv.reshape(actv.shape[0], len(numbers), len(sizes))\n",
    "            unit.fill_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
