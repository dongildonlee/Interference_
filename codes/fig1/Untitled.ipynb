{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e2f1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.append('../')\n",
    "from packages import actv_analysis, svm, load_csv, stats, objects\n",
    "import pickle\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=5; epoch=0\n",
    "# Load the list of objects from the file\n",
    "with open(f'network{net}_Relu{relu}_epoch{epoch}.pkl', 'rb') as f:\n",
    "    loaded_objects = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db494f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(2,21,2)\n",
    "sizes = np.arange(4,14)\n",
    "\n",
    "def process_unit_parallel(net, relu, epoch, numbers, sizes):\n",
    "    pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "    actv_net = actv_analysis.get_actv_net(net,relu,epoch)\n",
    "    avg_actv_net = np.mean(actv_net, axis=2)\n",
    "    avg_actv_nxs = avg_actv_net.reshape(avg_actv_net.shape[0], len(numbers), len(sizes))\n",
    "    units = None\n",
    "    try:\n",
    "        with open(pickle_filename, 'rb') as f:\n",
    "            units = pickle.load(f)\n",
    "            print(f'network{net}_Relu{relu}_epoch{epoch} is loaded')\n",
    "        for unit in units:\n",
    "            unit.PN = unit.find_PN(avg_actv_nxs)\n",
    "            unit.PS = unit.find_PS(avg_actv_nxs)\n",
    "        with open(pickle_filename, 'wb') as f:\n",
    "            pickle.dump(units, f)\n",
    "        print(f'network{net}_Relu{relu}_epoch{epoch} is clean')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred while processing file {pickle_filename}: {e}')\n",
    "    finally:\n",
    "        if units is not None:\n",
    "            del units  # make sure we free up memory\n",
    "            \n",
    "_ = Parallel(n_jobs=-1, verbose=50)(delayed(process_unit_parallel)(net, relu, epoch, numbers, sizes) for net in range(1,11) for relu in range(4,6) for epoch in range(0,91,10))\n",
    "\n",
    "# for net in range(1,2):\n",
    "#     for relu in range(5,6):\n",
    "#         for epoch in range(0,1,10):\n",
    "#             process_unit_parallel(net,relu,epoch,numbers,sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85299330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "for net in range(1, 11):  # replace with the actual range\n",
    "    for relu in range(4, 6):  # replace with the actual range\n",
    "        for epoch in range(0, 91, 10):  # replace with the actual range\n",
    "            # Run the function in parallel for each combination of network, layer, and epoch\n",
    "            stats.complete_anova2(net, relu, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7517cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=4; epoch=10\n",
    "min_sz_idx=3; max_sz_idx=9\n",
    "numbers=np.arange(2,21,2)\n",
    "inst=500\n",
    "\n",
    "stats.complete_anova2(net, relu, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=4; epoch=20\n",
    "print(f'Network{net} Relu{relu} Epoch{epoch}')\n",
    "\n",
    "pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "\n",
    "if os.path.exists(pickle_filename):\n",
    "    with open(pickle_filename, 'rb') as f:\n",
    "        units = pickle.load(f)\n",
    "    incomplete_units = np.array([i for i in range(len(units)) if not units[i].no_response_subset and (units[i].anova2 is None or units[i].anova2.isna().all().all())])\n",
    "    \n",
    "if len(incomplete_units) > 0:\n",
    "    # setup other parameters as required by add_anova2 function\n",
    "    min_sz_idx=3\n",
    "    max_sz_idx=9\n",
    "    numbers=np.arange(2,21,2)\n",
    "    inst=500\n",
    "\n",
    "    # prepare data\n",
    "    actv_net = actv_analysis.get_actv_net(net=net, relu=relu, epoch=epoch)\n",
    "    take = np.arange(0,100).reshape(10,10)[:,min_sz_idx:max_sz_idx+1].reshape(len(numbers)*(max_sz_idx-min_sz_idx+1))\n",
    "    actv_szAtoB = actv_net[:,take,:]\n",
    "    actv_2D = actv_szAtoB.reshape(actv_szAtoB.shape[0], actv_szAtoB.shape[1]*actv_szAtoB.shape[2])\n",
    "    sizes = np.arange(4,14)[min_sz_idx: max_sz_idx+1]\n",
    "\n",
    "    for unit_idx in incomplete_units:\n",
    "        try:\n",
    "            # run add_anova2 for the unit\n",
    "            units[unit_idx].add_anova2(actv_2D, numbers, sizes, inst, parallel=0)\n",
    "            print(f'Added anova2 for unit {unit_idx}')\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with unit {unit_idx}: {e}\")\n",
    "\n",
    "    # save the updated units back into the pickle file after processing all units\n",
    "    with open(pickle_filename, 'wb') as f:\n",
    "        pickle.dump(units, f)\n",
    "    print(f'Added anova2 for {len(incomplete_units)} units and saved to {pickle_filename}')\n",
    "else:\n",
    "    print(\"No incomplete units found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=1; relu=4\n",
    "num_incomplete = []\n",
    "for epoch in range(0,91,10):\n",
    "    print(f'Network{net} Relu{relu} Epoch{epoch}')\n",
    "    pickle_filename = f'network{net}_Relu{relu}_epoch{epoch}.pkl'\n",
    "    if os.path.exists(pickle_filename):\n",
    "        with open(pickle_filename, 'rb') as f:\n",
    "            units = pickle.load(f)\n",
    "            incomplete_units = np.array([i for i in range(len(units)) if not units[i].no_response_subset and (units[i].anova2 is None or units[i].anova2.isna().all().all())])\n",
    "            num_incomplete.append(len(incomplete_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b22e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91910102",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [(net, relu, epoch) \n",
    "         for net in range(1, 2)\n",
    "         for relu in range(4, 5)\n",
    "         for epoch in range(50, 71, 10)]\n",
    "\n",
    "# you could use Parallel to call this function multiple times in parallel\n",
    "results = Parallel(n_jobs=-1, verbose=10)(delayed(stats.complete_anova2)(*t) for t in tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ea9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "for net in range(1,11):\n",
    "    for relu in range(3,4):\n",
    "        for epoch in range(0,91,10):\n",
    "            stats.pkl_anova2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b8003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
