{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0bbb32-18be-40d0-be32-15b7c5026cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.append('../')\n",
    "\n",
    "from packages import actv_analysis, svm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2cfc18-7f8f-41ce-8b09-0011d8a682c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../pkl/4to20/network1_Relu4_epoch90_4to20.pkl..\n",
      "Loading actv ..\n",
      "--- 95.0904369354248 seconds ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m actv \u001b[38;5;241m=\u001b[39m actv_net\u001b[38;5;241m.\u001b[39mreshape(layer_numunits[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m percentage_true \u001b[38;5;129;01min\u001b[39;00m percentage_true_values:\n\u001b[0;32m---> 28\u001b[0m     random_units \u001b[38;5;241m=\u001b[39m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mktau\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercentage_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentage_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mupper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     31\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     32\u001b[0m     y_preds \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(svm\u001b[38;5;241m.\u001b[39mSVM_fit)(units\u001b[38;5;241m=\u001b[39mrandom_units, actv\u001b[38;5;241m=\u001b[39mactv, exp\u001b[38;5;241m=\u001b[39mexp) \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m exps)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "relus = list(range(4, 5))\n",
    "epochs = np.arange(0, 91, 10)\n",
    "num_units = 200\n",
    "layer_numunits = {'relu1':290400, 'relu2':186624, 'relu3':64896, 'relu4':64896, 'relu5':43264}\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath('..'))\n",
    "save_to_folder = f\"{dir_path}/dataframes/SVM_predictions\"\n",
    "\n",
    "exps = range(10)\n",
    "percentage_true_values = np.arange(0, 1.1, 0.1)\n",
    "\n",
    "for relu in relus:\n",
    "    for epoch in [90]:\n",
    "        for net in range(1, 4):\n",
    "            \n",
    "            pkl_filename = f'../../pkl/4to20/network{net}_Relu{relu}_epoch{epoch}_4to20.pkl'\n",
    "            print(f'Loading {pkl_filename}..')\n",
    "            with open(pkl_filename, 'rb') as f:\n",
    "                units = pickle.load(f)\n",
    "                    \n",
    "            print(f'Loading actv ..')\n",
    "            actv_net = actv_analysis.get_actv_net(net=net, relu=relu, epoch=epoch)\n",
    "            actv = actv_net.reshape(layer_numunits[f'relu{relu}'], 10, 10, 500)\n",
    "                    \n",
    "            for percentage_true in percentage_true_values:\n",
    "\n",
    "                random_units = svm.get_random_units(units, num_units=num_units, sort_by='ktau', percentage_true=percentage_true, \n",
    "                                                    upper_bound={'Q1':(1, 1),'Q2': (-0.1, 0.1),'Q3': (-1, -1),'Q4': (0.1, -0.1)}, Q1=True, Q3=True)\n",
    "\n",
    "                start_time = time.time()\n",
    "                y_preds = Parallel(n_jobs=-1)(delayed(svm.SVM_fit)(units=random_units, actv=actv, exp=exp) for exp in exps)\n",
    "                end_time = time.time()\n",
    "                print(f\"Took {end_time - start_time} seconds to run.\")\n",
    "\n",
    "                for exp in exps:\n",
    "                    filename = f'../../csv/SVM_prediction_He_untrained_net{net}_relu{relu}_epoch{epoch}_{num_units}_units_Q1_or_Q3_{percentage_true*100:.0f}percent_Q2Q4_abs_upper_bound01_exp{exp}_Oct2023.csv'\n",
    "                    pd.Series(y_preds[exp]).to_csv(filename, index=True)\n",
    "                    #print(f'Saved results to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f4db8-ce4b-4e4c-be9e-6a4e8de00d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net=1; relu=4; epoch=90\n",
    "num_units=200\n",
    "df_acc = pd.DataFrame(columns=['net','relu','epoch','percentage','exp','cong_acc','incong_acc'])\n",
    "\n",
    "for net in range(1,3):\n",
    "    for epoch in [90]:\n",
    "        for percentage_true in np.arange(0,1.1,0.1):\n",
    "            for exp in range(0,10):\n",
    "    \n",
    "                test_csv = f'../../csv/svm_test_set{exp}_4to20.csv'\n",
    "                pred_csv = f'../../csv/SVM_prediction_He_untrained_net{net}_relu{relu}_epoch{epoch}_{num_units}_units_Q1_or_Q3_{percentage_true*100:.0f}percent_coeff2_upper_bound02_exp{exp}_Oct2023.csv'\n",
    "                test_exp = pd.read_csv(test_csv, index_col=0)\n",
    "                num_dists=np.abs(test_exp['num1']-test_exp['num2'])*2\n",
    "                correct_answers = svm.get_y(test_exp).to_numpy()\n",
    "                svm_answers = pd.read_csv(pred_csv)['0'].to_numpy()\n",
    "                is_equal = np.equal(correct_answers, svm_answers)\n",
    "\n",
    "                cong = test_exp.index[((test_exp['num1']<test_exp['num2'])&(test_exp['sz1']<test_exp['sz2']))|((test_exp['num1']>test_exp['num2'])&(test_exp['sz1']>test_exp['sz2']))]\n",
    "                incong = np.setdiff1d(range(len(test_exp)), cong)\n",
    "                incong_acc = np.sum(is_equal[incong])/len(is_equal[incong])\n",
    "                cong_acc = np.sum(is_equal[cong])/len(is_equal[cong])\n",
    "                info = [net,relu,epoch,percentage_true,exp,cong_acc,incong_acc]\n",
    "                # Append info to df_acc\n",
    "                df_acc = pd.concat([df_acc, pd.DataFrame([info], columns=df_acc.columns)], ignore_index=True)\n",
    "                \n",
    "df_acc['complement_percentage'] = 1 - df_acc['percentage']\n",
    "\n",
    "# Save df_acc to a CSV file if needed\n",
    "#df_acc.to_csv('Quadrants_svm_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54a85c-5c74-4b78-8fff-d66873397328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_avg = df_acc.groupby(['net', 'relu', 'epoch', 'percentage', 'complement_percentage'])[['cong_acc', 'incong_acc']].mean().reset_index()\n",
    "\n",
    "# Filter the DataFrame to include only rows where epoch is 0\n",
    "df_epoch0 = df_avg[df_avg['epoch'] == 90]\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the line plot for incong_acc\n",
    "sns.lineplot(x='complement_percentage', y='incong_acc', data=df_epoch0, label='Incongruent Accuracy')\n",
    "\n",
    "# Create the line plot for cong_acc\n",
    "sns.lineplot(x='complement_percentage', y='cong_acc', data=df_epoch0, label='Congruent Accuracy')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Accuracy vs. Percentage for Epoch 0')\n",
    "plt.xlabel('Percentage of True Quadrants')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('coeff2_upper_bound_02.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc834d-4aca-43a3-9c84-4d577bf4539b",
   "metadata": {},
   "source": [
    "## Supplementary: congruency-coding units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736dc636-33a7-4743-9a2b-c25a177fb2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net=1; relu=4; epoch=90\n",
    "\n",
    "pkl_filename = f'../../pkl/4to20/network{net}_Relu{relu}_epoch{epoch}_4to20.pkl'\n",
    "print(f'Loading {pkl_filename}..')\n",
    "with open(pkl_filename, 'rb') as f:\n",
    "    units = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f05f1-a753-4b59-9949-6994bd0a1095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
